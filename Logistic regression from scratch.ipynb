{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(binary classification) from scratch in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start of by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the algorithm:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Logistic regression where we deal with binary classification problems we generally use the sigmoid function to specify the probability of one class with respect to the input example and the other class probability can be found by subtraction the earlier probability by 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function:\n",
    "g(z) = 1/(1 + exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model we can see logistic regression as a two layer model, one layer computing an affine transformation of the inputs with the specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine transformation:\n",
    "linear_pred = W<sup>T</sup> * x  (bias term is already included in W(parameters) and x<sub>0</sub> is 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the next layer implements sigmoid activation function to output probability of specified class i.e., output of second layer is:-\n",
    "\n",
    "1/(1 + exp(linear_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use maximum log-likelihood estimation as our cost function.\n",
    "\n",
    "Our update rule will be same as that for linear regression model(surprisingly both come the same after taking the derivatives and all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Pima Indians diabetes dataset for classification task.\n",
    "Dataset can be found here: https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.data.csv',delimiter=',',header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.iloc[:,:8]\n",
    "df_label = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(x,weights):\n",
    "    new_weights = np.array(weights)\n",
    "    new_array = x.reshape((x.shape[0],))\n",
    "    new_weights = new_weights.reshape((new_weights.shape[0],))\n",
    "    y = np.dot(new_weights,new_array)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    for j in range(x.shape[1]):\n",
    "        for i in range(x.shape[0]):\n",
    "            x[i,j] = (x[i,j] - np.amin(x[:,j]))/(np.amax(x[:,j])-np.amin(x[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data,ratio=0.8):\n",
    "    data_train = data[:int(ratio*data.shape[0]),:]\n",
    "    data_test  = data[int(ratio*data.shape[0]):,:]\n",
    "    return data_train,data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_split(data,ratio=0.8):\n",
    "    data_train = data[:int(ratio*data.shape[0])]\n",
    "    data_test  = data[int(ratio*data.shape[0]):]\n",
    "    return data_train,data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(train_data,train_target,lr,epochs):\n",
    "    weights = [0.0 for i in range(train_data.shape[1])]\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(train_data.shape[0]):\n",
    "            linear_pred = linear_layer(train_data[i,:],weights)\n",
    "            linear_pred = np.array(linear_pred)\n",
    "            y_pred = sigmoid(linear_pred) \n",
    "            y_pred = np.array(y_pred)\n",
    "            error = y_pred - train_target[i]\n",
    "            for j in range(train_data.shape[1]):\n",
    "                weights[j] = weights[j] - lr*error*y_pred*(1.0-y_pred)*train_data[i,j]\n",
    "    weights = np.array(weights)\n",
    "    return weights            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(train_data,train_target,test_data,lr,epochs):\n",
    "    predictions = []\n",
    "    weights = get_parameters(train_data,train_target,lr,epochs)\n",
    "    for i in range(test_data.shape[0]):\n",
    "        linear_pred = linear_layer(test_data[i,:],weights)\n",
    "        linear_pred = np.array(linear_pred)\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        predictions.append(y_pred)\n",
    "    predictions = np.array(predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(train_data,train_targets,test_data,test_targets,out_function,lr,epochs):\n",
    "    prediction = out_function(train_data,train_targets,test_data,lr,epochs)\n",
    "    prediction_labels = []\n",
    "    for i in range(len(prediction)):\n",
    "        if(prediction[i]>=0.5):\n",
    "            prediction_labels.append(1)\n",
    "        else:\n",
    "            prediction_labels.append(0)\n",
    "    accuracy = 0\n",
    "    for i in range(len(test_targets)):\n",
    "        if(prediction_labels[i] == test_targets[i]):\n",
    "            accuracy += 1\n",
    "    accuracy = accuracy/len(test_targets)        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now implementation and testing part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting pandas dataframe to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.as_matrix()\n",
    "df_label = df_label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('int64'))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.dtype , df_label.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data before using it to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "        0.48333333],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "        0.37901056],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "        0.39221783],\n",
       "       ...,\n",
       "       [1.        , 0.96031746, 1.        , ..., 0.86184211, 0.22781868,\n",
       "        0.6363187 ],\n",
       "       [1.        , 1.        , 0.85714286, ..., 0.99013158, 0.33418538,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 1.        , 0.29941165,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data = data_split(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels,test_labels = label_split(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614,), (154,))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape , test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting the bias column in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.insert(train_data,0,0.5,axis=1)\n",
    "test_data = np.insert(test_data,0,0.5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 9), (154, 9))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_parameters(train_data,train_labels,0.005,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_out = linear_layer(train_data[6],weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4583926225802051\n"
     ]
    }
   ],
   "source": [
    "print(lin_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_data,train_labels,test_data,test_labels,get_predictions,lr=0.1,epochs=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have our accuracy as 74.025% which is higher than the baseline i.e. 65% for this dataset with just basic logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
